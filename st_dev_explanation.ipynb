{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eea042d3",
   "metadata": {},
   "source": [
    "### The Practical Impact of Bessel's Correction\n",
    "\n",
    "Curious about why the variance formula divides by \\( n-1 \\) instead of n, I found the traditional explanation involving \"degrees of freedom\" unsatisfying. To gain a deeper understanding, I decided to investigate it myself. This experiment demonstrates the practical significance of **Bessel's correction** \\( n-1 \\) in the sample standard deviation formula. It highlights how **sample size** influences the accuracy of statistical estimators:\n",
    "\n",
    "- **Small Sample Sizes**:  \n",
    "  The correction is crucial, as using \\( n-1 \\) consistently outperforms \\( n \\). This helps mitigate the bias in estimating the population standard deviation.\n",
    "\n",
    "- **Large Sample Sizes**:  \n",
    "  The difference between \\( n \\) and \\( n-1 \\) becomes negligible, with \\( n \\) performing almost as well as \\( n-1 \\).\n",
    "\n",
    "This behavior aligns with **statistical theory**:  \n",
    "As the sample size increases, the bias corrected by \\( n-1 \\) diminishes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "618d070e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size 10: n-1 performed better in 65.00% of trials.\n",
      "Sample size 20: n-1 performed better in 60.00% of trials.\n",
      "Sample size 50: n-1 performed better in 55.40% of trials.\n",
      "Sample size 100: n-1 performed better in 50.20% of trials.\n",
      "Sample size 200: n-1 performed better in 49.60% of trials.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import sample\n",
    "\n",
    "trials = 500\n",
    "sample_sizes = [10, 20, 50, 100, 200]\n",
    "results = []\n",
    "\n",
    "# Run the experiment for each sample size\n",
    "for sample_size in sample_sizes:\n",
    "    count_n_minus_1_better = 0\n",
    "    \n",
    "    for _ in range(trials):\n",
    "        population = np.random.randn(3000)\n",
    "        population_std = population.std()\n",
    "        \n",
    "        abs_errors_n_minus_1 = []\n",
    "        abs_errors_n = []\n",
    "        \n",
    "        for _ in range(100):  \n",
    "            samples = np.array(sample(list(population), sample_size))\n",
    "            sample_mean = samples.mean()\n",
    "            st_dev_n_minus_1 = np.sqrt(np.sum((samples - sample_mean)**2) / (sample_size - 1))\n",
    "            st_dev_n = np.sqrt(np.sum((samples - sample_mean)**2) / sample_size)\n",
    "            \n",
    "            # Compute the absolute errors\n",
    "            abs_errors_n_minus_1.append(abs(st_dev_n_minus_1 - population_std))\n",
    "            abs_errors_n.append(abs(st_dev_n - population_std))\n",
    "        \n",
    "        # Compare the average errors for this trial\n",
    "        avg_error_n_minus_1 = np.mean(abs_errors_n_minus_1)\n",
    "        avg_error_n = np.mean(abs_errors_n)\n",
    "        \n",
    "        # Increment count if n-1 performs better\n",
    "        if avg_error_n_minus_1 < avg_error_n:\n",
    "            count_n_minus_1_better += 1\n",
    "    \n",
    "    results.append((sample_size, count_n_minus_1_better / trials))\n",
    "\n",
    "for sample_size, proportion in results:\n",
    "    print(f\"Sample size {sample_size}: n-1 performed better in {proportion:.2%} of trials.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
